

## Robots协议
* 域名/robots.txt
* 例如：https://zhuanlan.zhihu.com/robots.txt
```
User-agent: *         *表示所有搜索引擎准守
Disallow: /?s*        ?s*表示不能爬取带有“/?s”的路径
Disallow: /           表示所有内容都不能爬取
```

## Install
```
pip install beautifulsoup4
```











## 参考
bs4: https://beautifulsoup.cn/

